{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rketiel69/Images-to-PDF-8.8.1/blob/master/ml_pipeline/Movie_Recommender_DecisionTree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "hApke_Bfi-rj",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Import Librerie\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tarfile\n",
        "from six.moves import urllib\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
        "from sklearn import datasets, linear_model,tree\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download e formattazione dataset film\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/FiddiCoder/-FIA-Project/main/\"\n",
        "FILE_PATH = os.path.join(\"dataset\")\n",
        "FILE_URL1 = DOWNLOAD_ROOT + \"dataset/movies2\"\n",
        "\n",
        "def fetch_file_data1(file_url1=FILE_URL1, file_path1=FILE_PATH):\n",
        "    os.makedirs(file_path1, exist_ok=True)\n",
        "    csv_path1 = os.path.join(file_path1, \"movies2\")\n",
        "    urllib.request.urlretrieve(file_url1, csv_path1)\n",
        "\n",
        "fetch_file_data1()\n",
        "datapath = os.path.join(\"dataset\",\"\")\n",
        "\n",
        "with open('./dataset/movies2', encoding = \"ISO-8859-1\") as content:\n",
        "    colonne = ['movie_id', 'movie_title', 'release_date', 'video_release_date', 'imdb_url']\n",
        "    generi = ['unknown', 'action', 'adventure', 'animation', 'children', 'comedy', 'crime', 'documentary', 'drama', 'fantasy',\n",
        "          'film-noir',  'horror', 'musical', 'mystery', 'romance', 'sci-fi', 'thriller', 'war', 'western']\n",
        "    colonneG = colonne + generi\n",
        "    movies = pd.DataFrame(columns=colonneG)\n",
        "    i = 0\n",
        "    for x in content:\n",
        "        x = x.split(\"|\")\n",
        "        x[-1] = x[-1][:-1]\n",
        "        if x[1][-1] == ' ':\n",
        "            x[1] = x[1][:-1]\n",
        "        movies.loc[i] = [word if word!='' else \"empty\" for word in x]\n",
        "        i = i + 1\n",
        "movies['movie_id'] = movies['movie_id'].astype('int64')\n",
        "movies[generi] = movies[generi].astype('category')\n",
        "\n"
      ],
      "metadata": {
        "id": "x0fjqt_X8iBY",
        "cellView": "form"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data cleaning: Tabelle con feature inutili\n",
        "movies = movies.drop('video_release_date', axis=1)\n",
        "movies = movies.drop('release_date', axis=1)\n",
        "movies = movies.drop('imdb_url', axis=1)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HWZBgvREaK2A"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inserimento colonna target con relativo riempimento\n",
        "movies['like'] = 0\n",
        "\n",
        "for i in range(1600):\n",
        "  if((i % 3) == 0):\n",
        "    movies.loc[i, 'like'] = 1\n",
        "  if((i % 8) == 0):\n",
        "    movies.loc[i , 'like'] = 2\n",
        "  if((i % 7) == 0):\n",
        "     movies.loc[i , 'like'] = 3\n",
        "  if((i % 5) == 0):\n",
        "    movies.loc[i , 'like'] = 4\n",
        "  if((i % 6) == 0):\n",
        "    movies.loc[i , 'like'] = 5\n",
        "\n",
        "\n",
        "movies.head(100)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "phyekA1kaavQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Primo Test: Decision tree\n",
        "\n",
        "#@markdown Risultati scarsi.\n",
        "\n",
        "#@markdown Abbiamo pensato di joinare il dataset dei film con il dataset degli utenti che contiene a sua volta una variabile target (rating) con valori opportunamente riempiti e non inseriti manualmente da noi\n",
        "X = movies.iloc[:,2:20]\n",
        "print(X.columns)\n",
        "y = movies.iloc[:,21:]\n",
        "print(y.columns)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "test_size=0.20, random_state=0)\n",
        "\n",
        "dtree = tree.DecisionTreeClassifier()\n",
        "modello = dtree.fit(X_train.values, y_train)\n",
        "\n",
        "for i in range(1, len(movies)):\n",
        "    movie = movies.iloc[i, 1]\n",
        "    if(movie == 'Turbo: A Power Rangers Movie (1997)'):\n",
        "        movie_1_ind = movies.iloc[i,2:20]\n",
        "    if(movie == 'Dead Man Walking (1995)'):\n",
        "        movie_2_ind = movies.iloc[i,2:20]\n",
        "    if (movie == 'Chasing Amy (1997)'):\n",
        "        movie_3_ind = movies.iloc[i,2:20]\n",
        "\n",
        "print(\"prediction for Turbo: A Power Rangers Movie (1997)\")\n",
        "print(dtree.predict([movie_1_ind]))\n",
        "print(\"prediction for Dead Man Walking (1995)\")\n",
        "print(dtree.predict([movie_2_ind]))\n",
        "print(\"prediction for Chasing Amy (1997)\")\n",
        "print(dtree.predict([movie_3_ind]))\n",
        "print(\"\\n\")\n",
        "\n",
        "score = cross_val_score(modello, X_train, y_train, cv = 10)\n",
        "print(\"Cross validation: \\n\",score)\n",
        "print(\"Testing score: {}\".format(modello.score(X_test, y_test)))\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "c2BLRaVnx9rV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download txt utenti e formattazione in dataset\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/FiddiCoder/-FIA-Project/main/\"\n",
        "FILE_PATH = os.path.join(\"dataset\")\n",
        "FILE_URL1 = DOWNLOAD_ROOT + \"dataset/users.user\"\n",
        "\n",
        "def fetch_file_data1(file_url1=FILE_URL1, file_path1=FILE_PATH):\n",
        "    os.makedirs(file_path1, exist_ok=True)\n",
        "    csv_path1 = os.path.join(file_path1, \"users.user\")\n",
        "    urllib.request.urlretrieve(file_url1, csv_path1)\n",
        "\n",
        "fetch_file_data1()\n",
        "datapath = os.path.join(\"dataset\",\"\")\n",
        "\n",
        "colonne_user = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
        "users = pd.read_csv('./dataset/users.user', sep='|', names=colonne_user)\n"
      ],
      "metadata": {
        "id": "8BHKLaJ7IUPS",
        "cellView": "form"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data cleaning, trasformazione variabili da string a boolean\n",
        "\n",
        "#Drop feature inutile\n",
        "users = users.drop('zip_code', axis=1)\n",
        "\n",
        "#Data cleaning = Eliminazione righe vuote\n",
        "users = users[users['gender'] != 'empty']\n",
        "users = users[users['occupation'] != 'empty']\n",
        "\n",
        "#Colonne occupation e gender trasformate in più colonne coi rispettivi nomi delle variabili per dare loro valori booleani\n",
        "users['occupation'] = users['occupation'].astype('category')\n",
        "users['gender'] = users['gender'].astype('category')\n",
        "one_hot_occ = users.occupation.str.get_dummies()\n",
        "users = users.drop('occupation',axis=1)\n",
        "users = users.join(one_hot_occ,how='inner')\n",
        "one_hot_g = users.gender.str.get_dummies()\n",
        "users = users.drop('gender',axis=1)\n",
        "users = users.join(one_hot_g,how='inner')\n",
        "users.head(5)"
      ],
      "metadata": {
        "id": "NnuqVWMIfj0w",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download dataset chiave per joinare utenti e film\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/FiddiCoder/-FIA-Project/main/\"\n",
        "FILE_PATH = os.path.join(\"dataset\")\n",
        "FILE_URL1 = DOWNLOAD_ROOT + \"dataset/usersmovies.data\"\n",
        "\n",
        "def fetch_file_data1(file_url1=FILE_URL1, file_path1=FILE_PATH):\n",
        "    os.makedirs(file_path1, exist_ok=True)\n",
        "    csv_path1 = os.path.join(file_path1, \"usersmovies.data\")\n",
        "    urllib.request.urlretrieve(file_url1, csv_path1)\n",
        "\n",
        "fetch_file_data1()\n",
        "datapath = os.path.join(\"dataset\",\"\")\n",
        "\n",
        "colonnekey = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
        "key = pd.read_csv('./dataset/usersmovies.data', sep='\\t', names=colonnekey)\n",
        "\n",
        "#Drop feature inutile\n",
        "key = key.drop('timestamp', axis=1)\n",
        "key.head(50)"
      ],
      "metadata": {
        "id": "-x8SpRVYMDCD",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Drop vecchia colonna target 'like', da ora utilizzeremo 'rating'\n",
        "movies = movies.drop('like', axis=1)"
      ],
      "metadata": {
        "id": "LHYmqtkHN4ik",
        "cellView": "form"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Join dataset utenti e film\n",
        "final_dataset = key.merge(movies, left_on='movie_id', right_on='movie_id', how='inner')\n",
        "final_dataset = final_dataset.merge(users, left_on='user_id', right_on='user_id', how='inner')\n",
        "\n",
        "#Spostiamo la colonna target in ultima posizione\n",
        "sposta_colonna = final_dataset.pop(\"rating\")\n",
        "final_dataset.insert(46, \"rating\", sposta_colonna)\n",
        "\n",
        "final_dataset.head(10)"
      ],
      "metadata": {
        "id": "x3r5OP5LNZXk",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Secondo Test: Decision tree\n",
        "#@markdown Risultati ancora scarsi, se non peggiori.\n",
        "\n",
        "#@markdown Abbiamo di conseguenza pensato di trasformare la variabile target in un booleano, affinchè potesse risultare più semplice la classificazione tramite decision tree\n",
        "X = final_dataset.iloc[:,3:46]\n",
        "print(X.columns)\n",
        "y = final_dataset.iloc[:,46:]\n",
        "print(y.columns)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "test_size=0.20, random_state=0)\n",
        "\n",
        "dtree = tree.DecisionTreeClassifier()\n",
        "modello = dtree.fit(X_train.values, y_train)\n",
        "\n",
        "for i in range(1, len(final_dataset)):\n",
        "    movie = final_dataset.iloc[i, 2]\n",
        "    if(movie == 'Raising Arizona (1987)'):\n",
        "        movie_1_ind = final_dataset.iloc[i, 3:46]\n",
        "    if(movie == 'Little Big League (1994)'):\n",
        "        movie_2_ind = final_dataset.iloc[i, 3:46]\n",
        "    if (movie == 'Mighty Aphrodite (1995)'):\n",
        "        movie_3_ind = final_dataset.iloc[i, 3:46]\n",
        "print(\"prediction for Raising Arizona (1987))\")\n",
        "predict = dtree.predict([movie_1_ind])\n",
        "print(predict)\n",
        "print(\"prediction for Dead Man Walking (1995)\")\n",
        "predict = dtree.predict([movie_2_ind])\n",
        "print(predict)\n",
        "print(\"prediction for Chasing Amy (1997)\")\n",
        "predict = dtree.predict([movie_3_ind])\n",
        "print(predict)\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "score = cross_val_score(modello, X_train, y_train, cv = 10)\n",
        "print(\"cross validation scores: \\n\",score)\n",
        "print(\"testing score: {}\".format(modello.score(X_test, y_test)))\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "predict = dtree.predict(X_test)\n",
        "print('Accuracy modello: {0:0.4f}'.\n",
        "format(accuracy_score(y_test, predict)))\n",
        "\n",
        "cm = confusion_matrix(y_test, predict)\n",
        "print('Confusion matrix\\n\\n', cm)"
      ],
      "metadata": {
        "id": "B65CpYgDh6no",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Trasformazione colonna target in booleana\n",
        "\n",
        "#Vecchia implementazione, modificata dopo Quarto Test\n",
        "\n",
        "final_dataset['rating'] = final_dataset['rating'].replace(0,0)\n",
        "final_dataset['rating'] = final_dataset['rating'].replace(1,0)\n",
        "final_dataset['rating'] = final_dataset['rating'].replace(2,0)\n",
        "final_dataset['rating'] = final_dataset['rating'].replace(3,1)\n",
        "final_dataset['rating'] = final_dataset['rating'].replace(4,1)\n",
        "final_dataset['rating'] = final_dataset['rating'].replace(5,1)\n",
        "final_dataset.head(10)\n"
      ],
      "metadata": {
        "id": "TNC-4bOXhiER",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Terzo Test: Decision tree\n",
        "#@markdown Risultati considerevolmente migliori.\n",
        "#@markdown\n",
        "#@markdown Abbiamo pensato di fare Feature Selection per migliorare ulteriormente lo score.\n",
        "X = final_dataset.iloc[:,3:46]\n",
        "print(X.columns)\n",
        "y = final_dataset.iloc[:,46:]\n",
        "print(y.columns)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "test_size=0.20, random_state=0)\n",
        "\n",
        "dtree = tree.DecisionTreeClassifier()\n",
        "modello = dtree.fit(X_train.values, y_train)\n",
        "\n",
        "for i in range(1, len(final_dataset)):\n",
        "    movie = final_dataset.iloc[i, 2]\n",
        "    if(movie == 'Raising Arizona (1987)'):\n",
        "        movie_1_ind = final_dataset.iloc[i, 3:46]\n",
        "    if(movie == 'Little Big League (1994)'):\n",
        "        movie_2_ind = final_dataset.iloc[i, 3:46]\n",
        "    if (movie == 'Mighty Aphrodite (1995)'):\n",
        "        movie_3_ind = final_dataset.iloc[i, 3:46]\n",
        "print(\"prediction for Raising Arizona (1987))\")\n",
        "predict = dtree.predict([movie_1_ind])\n",
        "print(predict)\n",
        "print(\"prediction for Dead Man Walking (1995)\")\n",
        "predict = dtree.predict([movie_2_ind])\n",
        "print(predict)\n",
        "print(\"prediction for Chasing Amy (1997)\")\n",
        "predict = dtree.predict([movie_3_ind])\n",
        "print(predict)\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "score = cross_val_score(modello, X_train, y_train, cv = 10)\n",
        "print(\"Cross validation: \\n\",score)\n",
        "print(\"Testing score: {}\".format(modello.score(X_test, y_test)))\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "predict = dtree.predict(X_test)\n",
        "print('Accuracy modello: {0:0.4f}'.\n",
        "format(accuracy_score(y_test, predict)))\n",
        "\n",
        "cm = confusion_matrix(y_test, predict)\n",
        "print('Confusion matrix\\n\\n', cm)\n"
      ],
      "metadata": {
        "id": "3dVRP12uOV7c",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Feature Selection\n",
        "\n",
        "#Trasformazione variabili categoriche affinchè compaiano nella matrice di correlazione\n",
        "le = LabelEncoder()\n",
        "final_dataset['unknown'] = le.fit_transform(final_dataset['unknown'])\n",
        "final_dataset['action'] = le.fit_transform(final_dataset['action'])\n",
        "final_dataset['adventure'] = le.fit_transform(final_dataset['adventure'])\n",
        "final_dataset['animation'] = le.fit_transform(final_dataset['animation'])\n",
        "final_dataset['children'] = le.fit_transform(final_dataset['children'])\n",
        "final_dataset['comedy'] = le.fit_transform(final_dataset['comedy'])\n",
        "final_dataset['crime'] = le.fit_transform(final_dataset['crime'])\n",
        "final_dataset['documentary'] = le.fit_transform(final_dataset['documentary'])\n",
        "final_dataset['drama'] = le.fit_transform(final_dataset['drama'])\n",
        "final_dataset['fantasy'] = le.fit_transform(final_dataset['fantasy'])\n",
        "final_dataset['film-noir'] = le.fit_transform(final_dataset['film-noir'])\n",
        "final_dataset['horror'] = le.fit_transform(final_dataset['horror'])\n",
        "final_dataset['musical'] = le.fit_transform(final_dataset['musical'])\n",
        "final_dataset['mystery'] = le.fit_transform(final_dataset['mystery'])\n",
        "final_dataset['romance'] = le.fit_transform(final_dataset['romance'])\n",
        "final_dataset['sci-fi'] = le.fit_transform(final_dataset['sci-fi'])\n",
        "final_dataset['thriller'] = le.fit_transform(final_dataset['thriller'])\n",
        "final_dataset['war'] = le.fit_transform(final_dataset['war'])\n",
        "final_dataset['western'] = le.fit_transform(final_dataset['western'])\n",
        "\n",
        "#Matrice correlazione feature\n",
        "sns.set(rc = {'figure.figsize':(48,24)})\n",
        "sns.heatmap(final_dataset.corr(), annot = True, fmt='.2g',cmap= 'coolwarm')\n"
      ],
      "metadata": {
        "id": "LtYu639qw5kd",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Ordinamento correlazioni con feature target\n",
        "# Calcola la correlazione tra le feature e la colonna del rating\n",
        "correlation_matrix = final_dataset.corr()\n",
        "rating_correlation = correlation_matrix['rating'].drop('rating').drop('movie_id').drop('user_id')  # Rimuovi la correlazione con se stessa\n",
        "\n",
        "# Ordina le feature in base alla correlazione con il rating\n",
        "sorted_features = rating_correlation.abs().sort_values(ascending=False)\n",
        "\n",
        "# Stampa le feature ordinate per correlazione con il rating\n",
        "print(sorted_features)\n"
      ],
      "metadata": {
        "id": "f_TkvuLjqhug",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Prendiamo le migliori 24 feature\n",
        "\n",
        "final_dataset = final_dataset.drop('marketing',axis=1)\n",
        "final_dataset = final_dataset.drop('unknown',axis=1)\n",
        "final_dataset = final_dataset.drop('musical',axis=1)\n",
        "final_dataset = final_dataset.drop('sci-fi',axis=1)\n",
        "final_dataset = final_dataset.drop('salesman',axis=1)\n",
        "final_dataset = final_dataset.drop('artist',axis=1)\n",
        "final_dataset = final_dataset.drop('retired',axis=1)\n",
        "final_dataset = final_dataset.drop('other',axis=1)\n",
        "final_dataset = final_dataset.drop('adventure',axis=1)\n",
        "final_dataset = final_dataset.drop('technician',axis=1)\n",
        "final_dataset = final_dataset.drop('student',axis=1)\n",
        "final_dataset = final_dataset.drop('homemaker',axis=1)\n",
        "final_dataset = final_dataset.drop('animation',axis=1)\n",
        "final_dataset = final_dataset.drop('F',axis=1)\n",
        "final_dataset = final_dataset.drop('M',axis=1)\n",
        "final_dataset = final_dataset.drop('lawyer',axis=1)\n",
        "final_dataset = final_dataset.drop('programmer',axis=1)\n",
        "final_dataset = final_dataset.drop('documentary',axis=1)\n",
        "final_dataset = final_dataset.drop('thriller',axis=1)\n",
        "\n",
        "#Scartiamo le righe che hanno tutti i generi vuoti\n",
        "final_dataset = final_dataset.loc[~((final_dataset['drama'] == 0) & (final_dataset['comedy'] == 0) & (final_dataset['war'] == 0)\n",
        " & (final_dataset['horror'] == 0)  & (final_dataset['film-noir'] == 0) & (final_dataset['romance'] == 0)\n",
        "  & (final_dataset['children'] == 0) & (final_dataset['fantasy'] == 0) & (final_dataset['action'] == 0)\n",
        "  &  (final_dataset['mystery'] == 0) & (final_dataset['crime'] == 0) & (final_dataset['western'] == 0))\n",
        " ]\n",
        "\n",
        "#Scartiamo le righe che hanno tutti i dati dell'utente vuoti\n",
        "final_dataset = final_dataset.loc[~((final_dataset['healthcare'] == 0) & (final_dataset['age'] == 0) & (final_dataset['executive'] == 0)\n",
        " & (final_dataset['writer'] == 0)  & (final_dataset['educator'] == 0) & (final_dataset['administrator'] == 0)\n",
        "  & (final_dataset['scientist'] == 0) & (final_dataset['engineer'] == 0) & (final_dataset['librarian'] == 0)\n",
        "  & (final_dataset['doctor'] == 0) & (final_dataset['entertainment'] == 0) & (final_dataset['none'] == 0))]\n",
        "\n",
        "\n",
        "final_dataset.head(100)\n"
      ],
      "metadata": {
        "id": "_fzueg3Zqvdp",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Quarto test: Decision tree\n",
        "#@markdown Risultati di poco migliori.\n",
        "#@markdown\n",
        "#@markdown Raggiunto uno score dell'80% dopo la feature selection\n",
        "#@markdown\n",
        "#@markdown Si nota un'occorrenza sbilanciata di variabile target=0 rispetto a target=1\n",
        "#@markdown\n",
        "#@markdown Si è pensato dunque di bilanciare i dati attraverso undersampling\n",
        "\n",
        "X = final_dataset.iloc[:,3:27]\n",
        "print(X.columns)\n",
        "y = final_dataset.iloc[:,27:]\n",
        "print(y.columns)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "test_size=0.20, random_state=0)\n",
        "\n",
        "dtree = tree.DecisionTreeClassifier()\n",
        "modello = dtree.fit(X_train.values, y_train)\n",
        "\n",
        "for i in range(1, len(final_dataset)):\n",
        "    movie = final_dataset.iloc[i, 2]\n",
        "    if(movie == 'Raising Arizona (1987)'):\n",
        "        movie_1_ind = final_dataset.iloc[i, 3:27]\n",
        "    if(movie == 'Little Big League (1994)'):\n",
        "        movie_2_ind = final_dataset.iloc[i, 3:27]\n",
        "    if (movie == 'Mighty Aphrodite (1995)'):\n",
        "        movie_3_ind = final_dataset.iloc[i, 3:27]\n",
        "print(\"prediction for Raising Arizona (1987))\")\n",
        "predict = dtree.predict([movie_1_ind])\n",
        "print(predict)\n",
        "print(\"prediction for Dead Man Walking (1995)\")\n",
        "predict = dtree.predict([movie_2_ind])\n",
        "print(predict)\n",
        "print(\"prediction for Chasing Amy (1997)\")\n",
        "predict = dtree.predict([movie_3_ind])\n",
        "print(predict)\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "score = cross_val_score(modello, X_train, y_train, cv = 10)\n",
        "print(\"Cross validation: \\n\",score)\n",
        "print(\"Testing score: {}\".format(modello.score(X_test, y_test)))\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "predict = dtree.predict(X_test)\n",
        "print('Accuracy modello: {0:0.4f}'.\n",
        "format(accuracy_score(y_test, predict)))\n",
        "\n",
        "cm = confusion_matrix(y_test, predict)\n",
        "print('Confusion matrix\\n\\n', cm)"
      ],
      "metadata": {
        "id": "J9kIiDfJ4oEt",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Quinto test: Naive-Bayes\n",
        "#@markdown Risultati leggermente peggiori con Naive-Bayes\n",
        "X = final_dataset.iloc[:,3:27]\n",
        "print(X.columns)\n",
        "y = final_dataset.iloc[:,27:]\n",
        "print(y.columns)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=0\n",
        ")\n",
        "\n",
        "model = GaussianNB()\n",
        "\n",
        "modello = model.fit(X_train, y_train)\n",
        "\n",
        "for i in range(1, len(final_dataset)):\n",
        "    movie = final_dataset.iloc[i, 2]\n",
        "    if(movie == 'Raising Arizona (1987)'):\n",
        "        movie_1_ind = final_dataset.iloc[i, 3:27]\n",
        "        movie_1_real = final_dataset.iloc[i, 27]\n",
        "    if(movie == 'Little Big League (1994)'):\n",
        "        movie_2_ind = final_dataset.iloc[i, 3:27]\n",
        "        movie_2_real = final_dataset.iloc[i, 27]\n",
        "    if (movie == 'Mighty Aphrodite (1995)'):\n",
        "        movie_3_ind = final_dataset.iloc[i, 3:27]\n",
        "        movie_3_real = final_dataset.iloc[i, 27]\n",
        "print(\"prediction for Raising Arizona (1987))\")\n",
        "predict = model.predict([movie_1_ind])\n",
        "print(predict)\n",
        "print(\"Real value\")\n",
        "print(movie_1_real)\n",
        "print(\"prediction for Dead Man Walking (1995)\")\n",
        "predict = model.predict([movie_2_ind])\n",
        "print(predict)\n",
        "print(\"Real value\")\n",
        "print(movie_2_real)\n",
        "print(\"prediction for Chasing Amy (1997)\")\n",
        "predict = model.predict([movie_3_ind])\n",
        "print(predict)\n",
        "print(\"Real value\")\n",
        "print(movie_3_real)\n",
        "print(\"\\n\")\n",
        "\n",
        "score = cross_val_score(modello, X_train, y_train, cv = 10)\n",
        "print(\"Cross validation: \\n\",score)\n",
        "print(\"Testing score: {}\".format(modello.score(X_test, y_test)))\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuray = accuracy_score(y_pred, y_test)\n",
        "print(\"Accuracy:\", accuray)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NiBuFTXvzFpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Conta numero occorrenze valori variabile target\n",
        "# Conta il numero di righe in cui il valore della colonna è 1\n",
        "count_1 = len(final_dataset[final_dataset['rating'] == 1])\n",
        "\n",
        "# Conta il numero di righe in cui il valore della colonna è 0\n",
        "count_0 = len(final_dataset[final_dataset['rating'] == 0])\n",
        "\n",
        "# Stampa i risultati\n",
        "print(\"Numero di righe con valore 1:\", count_1)\n",
        "print(\"Numero di righe con valore 0:\", count_0)"
      ],
      "metadata": {
        "id": "utAR3lHsUVc7",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Undersampling\n",
        "# Determina il numero di righe da eliminare casualmente\n",
        "num_rows_to_drop = 60000  # Specifica il numero di righe da eliminare\n",
        "\n",
        "# Seleziona solo le righe con rating = 1 e determina l'indice di queste righe\n",
        "rows_to_drop = final_dataset.loc[final_dataset['rating'] == 1].index\n",
        "\n",
        "# Genera un array casuale di indici di riga da eliminare\n",
        "random_rows = np.random.choice(rows_to_drop, size=num_rows_to_drop, replace=False)\n",
        "\n",
        "# Elimina le righe casuali dal DataFrame\n",
        "final_dataset.drop(random_rows, inplace=True)\n",
        "\n",
        "\n",
        "# Conta il numero di righe in cui il valore della colonna è 1\n",
        "count_1 = len(final_dataset[final_dataset['rating'] == 1])\n",
        "\n",
        "# Conta il numero di righe in cui il valore della colonna è 0\n",
        "count_0 = len(final_dataset[final_dataset['rating'] == 0])\n",
        "\n",
        "# Stampa i risultati\n",
        "print(\"Numero di righe con valore 1:\", count_1)\n",
        "print(\"Numero di righe con valore 0:\", count_0)\n",
        "\n"
      ],
      "metadata": {
        "id": "mLCn6q4Fd9rV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Sesto test: Decision Tree\n",
        "X = final_dataset.iloc[:,3:27]\n",
        "print(X.columns)\n",
        "y = final_dataset.iloc[:,27:]\n",
        "print(y.columns)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "test_size=0.20, random_state=0)\n",
        "\n",
        "dtree = tree.DecisionTreeClassifier()\n",
        "modello = dtree.fit(X_train.values, y_train)\n",
        "\n",
        "for i in range(1, len(final_dataset)):\n",
        "    movie = final_dataset.iloc[i, 2]\n",
        "    if(movie == 'Raising Arizona (1987)'):\n",
        "        movie_1_ind = final_dataset.iloc[i, 3:27]\n",
        "    if(movie == 'Little Big League (1994)'):\n",
        "        movie_2_ind = final_dataset.iloc[i, 3:27]\n",
        "    if (movie == 'Mighty Aphrodite (1995)'):\n",
        "        movie_3_ind = final_dataset.iloc[i, 3:27]\n",
        "print(\"prediction for Raising Arizona (1987))\")\n",
        "predict = dtree.predict([movie_1_ind])\n",
        "print(predict)\n",
        "print(\"prediction for Dead Man Walking (1995)\")\n",
        "predict = dtree.predict([movie_2_ind])\n",
        "print(predict)\n",
        "print(\"prediction for Chasing Amy (1997)\")\n",
        "predict = dtree.predict([movie_3_ind])\n",
        "print(predict)\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "score = cross_val_score(modello, X_train, y_train, cv = 10)\n",
        "print(\"Cross validation: \\n\",score)\n",
        "print(\"Testing score: {}\".format(modello.score(X_test, y_test)))\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "predict = dtree.predict(X_test)\n",
        "print('Accuracy modello: {0:0.4f}'.\n",
        "format(accuracy_score(y_test, predict)))\n",
        "\n",
        "cm = confusion_matrix(y_test, predict)\n",
        "print('Confusion matrix\\n\\n', cm)"
      ],
      "metadata": {
        "id": "eMrWcjJ9huKx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Settimo test: Naive-Bayes\n",
        "X = final_dataset.iloc[:,3:27]\n",
        "print(X.columns)\n",
        "y = final_dataset.iloc[:,27:]\n",
        "print(y.columns)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=0\n",
        ")\n",
        "\n",
        "model = GaussianNB()\n",
        "\n",
        "modello = model.fit(X_train, y_train)\n",
        "\n",
        "for i in range(1, len(final_dataset)):\n",
        "    movie = final_dataset.iloc[i, 2]\n",
        "    if(movie == 'Raising Arizona (1987)'):\n",
        "        movie_1_ind = final_dataset.iloc[i, 3:27]\n",
        "        movie_1_real = final_dataset.iloc[i, 27]\n",
        "    if(movie == 'Little Big League (1994)'):\n",
        "        movie_2_ind = final_dataset.iloc[i, 3:27]\n",
        "        movie_2_real = final_dataset.iloc[i, 27]\n",
        "    if (movie == 'Mighty Aphrodite (1995)'):\n",
        "        movie_3_ind = final_dataset.iloc[i, 3:27]\n",
        "        movie_3_real = final_dataset.iloc[i, 27]\n",
        "print(\"prediction for Raising Arizona (1987))\")\n",
        "predict = model.predict([movie_1_ind])\n",
        "print(predict)\n",
        "print(\"Real value\")\n",
        "print(movie_1_real)\n",
        "print(\"prediction for Dead Man Walking (1995)\")\n",
        "predict = model.predict([movie_2_ind])\n",
        "print(predict)\n",
        "print(\"Real value\")\n",
        "print(movie_2_real)\n",
        "print(\"prediction for Chasing Amy (1997)\")\n",
        "predict = model.predict([movie_3_ind])\n",
        "print(predict)\n",
        "print(\"Real value\")\n",
        "print(movie_3_real)\n",
        "print(\"\\n\")\n",
        "\n",
        "score = cross_val_score(modello, X_train, y_train, cv = 10)\n",
        "print(\"Cross validation: \\n\",score)\n",
        "print(\"Testing score: {}\".format(modello.score(X_test, y_test)))\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuray = accuracy_score(y_pred, y_test)\n",
        "print(\"Accuracy:\", accuray)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M4rfIh27jX6d",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}